--- 
layout: single
classes: wide
title: "[AI/ML] "
header:
  overlay_image: /img/ai-ml-bg.png
excerpt: ''
author: "window_for_sun"
header-style: text
categories :
  - AI/ML
tags:
    - Practice
    - ML
toc: true
use_math: true
---

## ML
`Machine Learning(ML)` 은 컴퓨터가 데이터를 통해 학습하고 예측을 수행하는 기술을 의미한다. 
이런 `ML` 알고리즘을 간단하게 표현하면 `선을 긋는 것` 이라고 할 수 있다.
이후 설명에서는 이런 `선을 긋는 것` 이 어떠한 의미를 가지는 것인지 살펴본다.  

### Classification
`Classification` 은 데이터를 분류하는 작업을 의미한다. 
예를 들어, `사과` 와 `오렌지` 를 구분하는 작업을 가정해 볼 것이다. 
많은 사과와 오렌지 이미지를 모아두면, 
각 이미지에서 과일의 색상과 크기를 추출할 수 있고 이런 특징을 바탕으로 `사과` 와 `오렌지` 를 구분한다고 가정해본다. 
이때 가장 첫 단계는 `labled training data` 즉 라벨링된 학스 데이터를 얻는 것이다. 
그러므로 `사과`, `오렌지` 로 라벨링된 많은 과일 이미지를 확보하는 것이 가장 첫 단계로 필요하다. 
해당 이미지를 바탕으로 색상과 크기 정보를 추출한 뒤, 이 추출 데이터가 사과인지 오렌지인지 판별하는데 있어 어떠한 관계가 있는지 확인 할 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-1.drawio.png)

`붉은 점` 은 사과로 라벨링된 데이터이고, `주황색 점` 은 오렌지로 라벨링된 데이터이다. 
전체 데이터를 모아 그래프에서 전체적으로 보면 라벨링된 데이터들에 특정 패턴이 있다는 것을 알 수 있다. 
사과는 대부분 빨간색이므로 그래프 좌측에 모이고, 오렌지는 주황색이기 대문에 오른쪽에 모이는 것을 볼 수 있다. 
그리고 구현하고자 하는 최종 알고리즘은 이런 패턴을 학습하도록 하는 것이다.  

알고리즘이 가장 첫 목표는 두 리벨 그룹 사이에 `decision boundary` 인 결정 경계라는 선을 그리도록 하는 것이다. 
그리고 선은 아래와 같이 그을 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-2.drawio.png)

위와 같이 현 예제에서 라벨링된 데이터를 바탕으로 사과와 오렌지는 구분은 직선 하나로 가능하다. 
물론 더 복잡한 `ML` 알고리즘은 직선이 아닌 아래와 같은 더 복잡한 선을 그릴 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-3.drawio.png)


라벨링된 학습 데이터를 사용했고, 이를 통해 사과와 오렌지를 구분하는 선을 그었다. 
해당 선을 바탕으로 새로운 이미지에서도 사과와 오렌지를 구분할 수 있을 것이다. 
만약 아래와 같이 `파란 점` 으로 표시된 과일 이미지를 받는다면, 우리가 학습시킨 결정 경계를 바탕으로 해당 과일 이미지는 오렌지로 분류할 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-4.drawio.png)


이것이 바로 `ML` 을 통해 도출해 낼 수 있는 결과물이고, 
이렇게 학습 데이터를 바탕으로 `ML` 알고리즘을 수행해 데이터들 사이에 선을 그어 이를 새로운 데이터에도 적용할 수 있다. 
이렇게 데이터를 구분하기 위해 선을 긋는 `ML` 유형을 `Classification` 분류라고 한다. 
그리고 다른 하위 분야인 `Regression` 회귀는 데이터를 설명하는 선을 그리는 것과 관련이 있는데 이는 아래에서 좀 더 상세히 알아본다.  

### Regression
`Regression` 회귀는 데이터를 설명하는 선을 그리는 작업을 의미한다.
다양한 주택의 가격과 해당 주택의 면적에 관한 리벨링된 데이터가 있다고 가정한다. 
그리고 이 데이터는 아래와 같이 시각화할 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-5.drawio.png)


각 `푸른 점` 은 주택의 면적과 가격을 나타내는 데이터를 의미하는데, 
데이터가 흩뿌려져 있는 것 같지만 동시에 특정 할 수 있는 패턴이 있다는 것도 알 수 있다. 
즉 주택이 클수록 가격이 비싸다는 경향이 있고, 이러한 패턴을 통해 주택 크기에 따라 가격을 예측할 수 있는 알고리즘을 설계할 수 있다.  

위 시각화된 데이터가 대각선 방향으로 흩뿌려져 있는 것을 볼 수 있는데, 
이를 일반화해 주택이 대각선 방향의 데이터 군집에 위치할 가능성이 높다고 판단할 수 있다. 
아래 그림에서 새로운 주택 데이터가 `초록 점` 에 위치할 가능성은 매우 높고, 
`빨간 점` 에 위치할 가능성은 매우 낮다고 할 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-6.drawio.png)


이러한 패턴을 좀 더 일반화하면, 주어진 면적에 대해 주택 가격이 얼마인지 정확한 답은 구하기 어렵지만, 
대략적인 답은 구하기 쉽다. 
이런 일반화를 위해 흩뿌려져 있는 데이터 군집을 가로지르는 각 데이터에 가장 가까운 선을 그린다. 
이러한 선을 `predicator` 예측기라고 하고, 이를 바탕으로 주택 면적을 기반으로 주택 가격을 예측할 수 있다. 
해당 대각선을 통해 주어진 주택 면적에 대한 가능성이 높은 주택가격을 도출할 수 있다. 
이를 다른 의미로 표현하면 해당 예측기는 주어진 면적에 대한 주택 가격의 `평균` 을 예측한다고 할 수 있다.  

![그림 1]({{site.baseurl}}/img/aiml/aiml-ml-basics-part1-7.drawio.png)


예측기인 선이 반드시 선형(`linear`) 이어야 하는 것은 아니다. 
예측기는 알고 있는 다양하고 좀 더 복잡한 함수 나 모델(이차 함수, 사인 함수, 임의의 함수 등) 일 수 있다. 
예측기에 복잡한 모델을 사용한다고 해서 예측값의 정확도가 올라간다고 할 수 있는 것이 아니기 때문에, 
어떤 모델을 사용할지는 문제에 따라 데이터에 따라 달라 질 수 있음을 기억해야 한다.  

현재 구현된 예측기는 하나의 입력 변수(주택 면적)를 가지고 있지만, 
위치, 건축 자제 등 더 많은 정보를 함께 고려할 수도 있다. 
그러면 그래프는 3차원이상으로 확장되고, 예측기는 면적과 위치, 건축 자재 등을 고려한 복잡한 모델이 될 것이다.  

만약 그래프가 3차원이라도 데이터를 기반으로 예측기를 그릴 수 있는데, 이때는 선이 아니라 편면을 그려야 할 것이다. 
즉 주택 가격을 예측하기 위해 면적과 위치, 건축 자재 등을 고려한 예측기를 그려야 하기 때문이다.  

실제로 더 복잡한 `ML` 학습 알고리즘에서는 수백 개에서 수천 개의 변수를 사용해 결과를 고려할 수 있다.  

### Predictor
`Predictor` 예측기는 데이터를 바탕으로 예측을 수행하는 모델을 의미한다. 
앞선 언급처럼 예측기에는 다양한 종류가 있고, 위 글에서 사용한 것은 선형 예측기이다.
이런 선형 예측기를 수학적 형태로 표현하면 아래와 같다.


$$
f(x) = c_nx_n + c_{n-1}x_{n-1} + ... + c_1x_1 + c_0x_0
$$


위 식에서 `x` 는 면적이나 생활비 같은 서로 다른 입력 특성을 나타내고, 
`c` 는 파라미터, 가중치 라고 부른다. 
특정 가중치가 클수록 모델이 해당 특성을 더 중요하게 고려한다는 의미이다. 
주택 면적의 경우 주택 가격 예측에 좋은 변수 이므로, 
알고리즘에서 해당 변수의 가중치를 높여 해당 변수를 더 중요하게 고려할 수 있다. 
그리고 주택 콘센트의 수와 같은 변수는 주택 가격 예측에 중요하지 않은 변수이므로 해당 변수의 가중치를 낮출 수 있다.  

결과적으로 주택 크기에 따른 주택 가격을 예측하는 경우에는 면적이라는 하나의 변수만 고려하기 때문에, 
입력 `x` 는 하나만 필요하므로 아래와 같이 정의할 수 있다.  


$$
y(x) = c_1x + c_0
$$

그리고 이는 아래와 같이 좀 더 일반화해 표현할 수도 있다.  


$$
y(x) = mx + b
$$


`y(x)` 는 출력 값 즉 주택 가격이고, `x` 는 입력 특성인 주택 크기, 
$c_0$ 는 `y` 축과 만나는 지점으로 `x` 가 0일 때 `y` 의 값을 의미한다. 
즉 이는 `y` 절편(`intercept`) 이라고 라고 불리며, 주택의 기본 가격을 의미한다.
이런 $c_0$ 를 사용해 예측모델 전반의 편항(`bias`) 을 조정할 수 있다.  


여기서 중요한 점은 `ML` 알고리즘에서 예측 결과를 잘 도출할 수 있는 가중치/파라미터($c_1$, $c_0$) 를 어떻게 찾을 지에 대한 고민이 남는다. 
먼저 `정규 방정식`(`normal equation`) 이라는 방법을 사용해 가중치를 찾을 수 있지만, 
이는 행렬을 통해 계수를 작접 계산하는 방법으로 한 번의 계산으로 정확한 해를 구할 수는 있지만, 
변수가 많이질 수록 계산 비용이 급격히 증가한다는 점이있다.  
그래서 일반적으로 이후에 더 자세히 알아볼 `Gradient Descent` 방법을 사용해 가중치를 찾는다. 
이는 반복적인 알고리즘으로 대규모 데이터셋에서도 효율적으로 가중치를 찾을 수 있다. 

