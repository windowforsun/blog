--- 
layout: single
classes: wide
title: "[Kafka] Kafka CDC Outbox"
header:
  overlay_image: /img/kafka-bg.jpg
excerpt: 'Kafka CDC Outbox 를 활용한 데이터 변경 캡쳐 및 전파 방식에 대해 알아보자'
author: "window_for_sun"
header-style: text
categories :
  - Kafka
tags:
    - Practice
    - Kafka
    - Kafka Connect
    - Debezium
    - CDC
    - Outbox
    - MSA
    - Event Driven
    - Kafka Topic
    - Kafka Producer
    - Kafka Consumer
    - Kafka Streams
toc: true
use_math: true
---  

## Kafka CDC Outbox
`Kafka CDC Outbox`(데이터 변경 캡쳐)는 `MSA` 에서 데이터의 일관성 있는 전파와 통합을 위한 강력한 패턴이다. 
`MSA` 를 구성하는 각 서비스에서 데이터를 변경 할 떄 발생하는 이벤트를 캡쳐하고 이를 `Kafka` 를 통해 다른 서비스로 전달하는 방식으로 동작한다. 
이를 활용하면 데이터 일관성을 유지하면서 서비스간 느슨한 결합을 구현 할 수 있다.  

`MSA` 는 각 서비스가 다루는 데이터를 전파하고 데이터 변경 사항을 전달하는 방식으로 구성된다. 
구매 주문을 관리하는 `MSA` 가 있다고 가정하면, 새로운 주문이 접수되면 그 주문에 대한 정보가 배승 서비스와 고객 서비스로 전달되는 것이 필요하다.  

주문 서비스가 새로운 주문에 대해 다른 서비스에 해당 사항을 전파하는 방식에는 다양한 방법이 있다. 
가장 대표적인 방법이 `REST API` 와 같은 것을 이용해 동기적으로 호출하는 것이다. 
하지만 이런 방식에는 의도치 않은 강한 결합을 생성할 수 있다. 
주문 서비스가 `REST API` 를 통해 각 서비스에 전파하기 위해서는 전파해야 하는 대상 서비스의 위치(도메인)과 
해당 서비스가 전파를 받을 수 있는 상태인지 등을 고려해야하 한다. 
만약 일시적으로 가용불가 상태라면 이후 재전송처리는 어떻게 할지도 고민이 필요하다.  

이러한 동기적인 전달방식의 문제점은 두 엔드포인트가 모두 존재하고 가용 가능상태여야 이벤트 전달이 가능하다는 것이다. 
또한 두 엔드포인트간 이벤트를 전달 할때 한쪽이 빠르게 전달하면, 받는 쪽은 그 속도에 맞춰 이벤트를 받아 처리해야 한다. 
즉 이벤트 전달에 있어서 버퍼링 혹은 `backpressure` 의 역할이 없으므로 이에 대한 고민도 필요하다. 
또한 새로 실행된 인스턴스의 경우 이전 이벤트를 수신할 수 없다는 점도 있다.  

이렇게 동기적인 방식에 따른 문제점들은 비동기 이벤트 전달 방식을 사용하면 해결 가능하다. 
즉 이벤트를 각 목적에 맞는 `Kafka Topic` 과 같은 것을 사용해서 이벤트를 전파하는 것이다. 
그리고 이벤트가 필요한 서비스는 해당 토픽을 구독해 이벤트 스트림상에 전달되는 변경사항을 받아 목적에 맞는 처리를 수행 할 수 있다.  

이러한 비동기 방식이 장점 중 하나는 이벤트를 전달하는 서비스와는 별도로 해당 이벤트가 필요로하는 서비스를 필요에 따라 추가할 수 있다는 점이다. 
이는 초기 구현에는 고려되지 못했던 다양한 케이스에 대해 유연하게 대응 가능하다는 장점이 있다. 
주문에 대한 이벤트를 기존에는 배송 서비스에서만 변경사항을 받아 처리했는데 
이후 더 추가적인 로깅 혹은 분석을 위해 `Elasticsearch` 에 저장하는 등으로 확장이 가능하다. 
또한 `Kafka Topic` 은 일정기간 메시지를 보존 할 수 있는데 이를 통해 이전 이벤트 히스토리를 파악한다던가, 
새롭게 투입되는 서비스에서도 이벤트 히스토리를 재생해 기반 데이터를 구축 할 수 있다.  

해당 포스팅에서 사용하는 코드 예시 및 데모 프로젝트의 전체 내용은 [여기](https://github.com/windowforsun/cdc-outbox-exam)
에서 확인 할 수 있다.  

### Dual Writes Issue
`Dual Writes` 이중 쓰기는 비동기 방식으로 이벤트를 전달 할 때 흔히 발생할 수 있는 문제점이다. 
주문 서비스와 배송 서비스가 비동기로 이벤트를 주고 받는다고 가정해보자. 
주문 서비스에 새로운 주문이 들어오면 주문 테이블에 새로운 레코드롤 `INSERT` 한 후 주문에 대한 `Kafka Topic` 에 이벤트를 발생 할 것이다. 
그리고 배송 서비스는 주문 `Topic` 에서 이벤트를 받아 배송에 대한 처리를 수행한다.  

하지만 이러한 비동기 방식은 [Kafka Consumer Duplication Patterns](2024-02-01-kafka-practice-kafka-duplication-patterns.md)
에서 설명한 것처럼 비동기라는 특성으로 인해 서로간 불일치가 발생 할 수 있다. 
이는 주문 서비스에서 `DB` 에 레코드를 `INSERT` 하고 `Apache Kafka` 에 메시지를 보내는 두 동작을 의미한다. 
그 이유는 `Apache Kafka` 와 데이터베이스를 하나의 트랜잭션으로 묶을 수 없기 때문이다. 
주문 레코드는 `INSERT` 됐지만, `Apache Kafka` 로 주문에 대한 이벤트 전달이 실패하는 것과 같은 증상이 충분히 발생 할 수 있다는 의미이다.  

이러한 문제점의 간단한 해결방법은 주문 서비스에서 `Apache Kafka` 혹은 데이터베이스 둘 중 하나에만 쓰기 동작을 수행해 일관성을 보장하는 것이다. 
우선 주문 서비스에서 `Apache Kafka` 에만 새로운 주문에 대한 이벤트를 전송하고 해당 이벤트를 받은 이후 새로운 주문 레코드를 `INSERT` 하는 경우이다. 
하지만 이런 방식을 사용하면 전체 주문을 조회하는 경우 비동기라는 특성으로 인해 새로운 주문이 누락될 수 있다는 문제점이 있다.  

다음으로 알아볼 방법이 데이터베이스에 동기적으로 쓰고, 이를 기반으로 `Apache Kafka` 에 메시지를 보내는 경우인데 이것을 `Outbox Pattern` 이라고 부른다. 
이에 대한 내용은 아래 챕터에서 별도로 다룬다.  


### Outbox Pattern
`Outbox Pattern` 의 기반 아이디어는 데이터베이스에 이벤트를 담는 `Outbox` 테이블을 두는 것이다. 
주문 서비스에서 새로운 주문이 들어오면 신규 주문에 대한 레코드를 `INSERT` 하고, 
동일 트랜잭션에서 `Outbox` 테이블에도 해당 이벤트를 나타내는 레코드를 `INSERT` 하는 방식이다.  

`Outbox` 테이블에 추가되는 레코드는 발생한 이벤트를 의미한다. 
이는 신규 주문을 의미하는 이벤트를 나타내는 `JSON` 일 수도 있고, 주문 변경에 대한 이벤트일 수도있다. 
그리고 필요에 따라 주문을 식별하는 식별자나 타입등의 이벤트 처리를 위한 다양한 컨텍스트를 포함 할 수 있다.  

그리고 `Outbox` 테이블의 변경을 모니터링하는 비동기 프로세스가 `Apache Kafka` 로 해당 테이블의 변경사항을 전파한다. 
이러한 개념을 통해 우리는 신규 주문에 대한 데이터를 `INSERT` 하는 동작과 신규 주문 이벤트를 전파하는 것을 하나의 데이터베이스 트랜잭션으로 묶을 수 있다. 
이는 신규 주문에 대한 데이터베이스 쓰기 동작과 이벤트 전파 동작이 모두 커밋되어 성공하거나, 둘중 하나라도 실패해 모두 실패하는 결과를 얻을 수 있다. 
또한 신규 주문 이후 바로 전체 주문을 조회하더라도 자신이 쓴 주문을 포함해 모두 조회 할 수도 있다.  

여기서 우리가 좀 더 알아봐야 할 것은 바로 `Outbox` 테이블의 변경사항을 어떻게 모니터링 하고, 
이를 `Apache Kafka` 로 밀어 넣어주냐인데 우리는 `Debezium` 과 `CDC`(데이터 변경 캡쳐)를 사용해 이를 손쉽게 해결하고 활용 할 수 있다.  

