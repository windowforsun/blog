--- 
layout: single
classes: wide
title: "[Kafka] Kafka CDC Outbox"
header:
  overlay_image: /img/kafka-bg.jpg
excerpt: 'Kafka CDC Outbox 를 활용한 데이터 변경 캡쳐 및 전파 방식에 대해 알아보자'
author: "window_for_sun"
header-style: text
categories :
  - Kafka
tags:
    - Practice
    - Kafka
    - Kafka Connect
    - Debezium
    - CDC
    - Outbox
    - MSA
    - Event Driven
    - Kafka Topic
    - Kafka Producer
    - Kafka Consumer
    - Kafka Streams
toc: true
use_math: true
---  

## Kafka CDC Outbox
`Kafka CDC Outbox`(데이터 변경 캡쳐)는 `MSA` 에서 데이터의 일관성 있는 전파와 통합을 위한 강력한 패턴이다. 
`MSA` 를 구성하는 각 서비스에서 데이터를 변경 할 떄 발생하는 이벤트를 캡쳐하고 이를 `Kafka` 를 통해 다른 서비스로 전달하는 방식으로 동작한다. 
이를 활용하면 데이터 일관성을 유지하면서 서비스간 느슨한 결합을 구현 할 수 있다.  

`MSA` 는 각 서비스가 다루는 데이터를 전파하고 데이터 변경 사항을 전달하는 방식으로 구성된다. 
구매 주문을 관리하는 `MSA` 가 있다고 가정하면, 새로운 주문이 접수되면 그 주문에 대한 정보가 배승 서비스와 고객 서비스로 전달되는 것이 필요하다.  

주문 서비스가 새로운 주문에 대해 다른 서비스에 해당 사항을 전파하는 방식에는 다양한 방법이 있다. 
가장 대표적인 방법이 `REST API` 와 같은 것을 이용해 동기적으로 호출하는 것이다. 
하지만 이런 방식에는 의도치 않은 강한 결합을 생성할 수 있다. 
주문 서비스가 `REST API` 를 통해 각 서비스에 전파하기 위해서는 전파해야 하는 대상 서비스의 위치(도메인)과 
해당 서비스가 전파를 받을 수 있는 상태인지 등을 고려해야하 한다. 
만약 일시적으로 가용불가 상태라면 이후 재전송처리는 어떻게 할지도 고민이 필요하다.  

이러한 동기적인 전달방식의 문제점은 두 엔드포인트가 모두 존재하고 가용 가능상태여야 이벤트 전달이 가능하다는 것이다. 
또한 두 엔드포인트간 이벤트를 전달 할때 한쪽이 빠르게 전달하면, 받는 쪽은 그 속도에 맞춰 이벤트를 받아 처리해야 한다. 
즉 이벤트 전달에 있어서 버퍼링 혹은 `backpressure` 의 역할이 없으므로 이에 대한 고민도 필요하다. 
또한 새로 실행된 인스턴스의 경우 이전 이벤트를 수신할 수 없다는 점도 있다.  

이렇게 동기적인 방식에 따른 문제점들은 비동기 이벤트 전달 방식을 사용하면 해결 가능하다. 
즉 이벤트를 각 목적에 맞는 `Kafka Topic` 과 같은 것을 사용해서 이벤트를 전파하는 것이다. 
그리고 이벤트가 필요한 서비스는 해당 토픽을 구독해 이벤트 스트림상에 전달되는 변경사항을 받아 목적에 맞는 처리를 수행 할 수 있다.  

이러한 비동기 방식이 장점 중 하나는 이벤트를 전달하는 서비스와는 별도로 해당 이벤트가 필요로하는 서비스를 필요에 따라 추가할 수 있다는 점이다. 
이는 초기 구현에는 고려되지 못했던 다양한 케이스에 대해 유연하게 대응 가능하다는 장점이 있다. 
주문에 대한 이벤트를 기존에는 배송 서비스에서만 변경사항을 받아 처리했는데 
이후 더 추가적인 로깅 혹은 분석을 위해 `Elasticsearch` 에 저장하는 등으로 확장이 가능하다. 
또한 `Kafka Topic` 은 일정기간 메시지를 보존 할 수 있는데 이를 통해 이전 이벤트 히스토리를 파악한다던가, 
새롭게 투입되는 서비스에서도 이벤트 히스토리를 재생해 기반 데이터를 구축 할 수 있다.  

해당 포스팅에서 사용하는 코드 예시 및 데모 프로젝트의 전체 내용은 [여기](https://github.com/windowforsun/cdc-outbox-exam)
에서 확인 할 수 있다.  

### Dual Writes Issue
`Dual Writes` 이중 쓰기는 비동기 방식으로 이벤트를 전달 할 때 흔히 발생할 수 있는 문제점이다. 
주문 서비스와 배송 서비스가 비동기로 이벤트를 주고 받는다고 가정해보자. 
주문 서비스에 새로운 주문이 들어오면 주문 테이블에 새로운 레코드롤 `INSERT` 한 후 주문에 대한 `Kafka Topic` 에 이벤트를 발생 할 것이다. 
그리고 배송 서비스는 주문 `Topic` 에서 이벤트를 받아 배송에 대한 처리를 수행한다.  

하지만 이러한 비동기 방식은 [Kafka Consumer Duplication Patterns](2024-02-01-kafka-practice-kafka-duplication-patterns.md)
에서 설명한 것처럼 비동기라는 특성으로 인해 서로간 불일치가 발생 할 수 있다. 
이는 주문 서비스에서 `DB` 에 레코드를 `INSERT` 하고 `Apache Kafka` 에 메시지를 보내는 두 동작을 의미한다. 
그 이유는 `Apache Kafka` 와 데이터베이스를 하나의 트랜잭션으로 묶을 수 없기 때문이다. 
주문 레코드는 `INSERT` 됐지만, `Apache Kafka` 로 주문에 대한 이벤트 전달이 실패하는 것과 같은 증상이 충분히 발생 할 수 있다는 의미이다.  

이러한 문제점의 간단한 해결방법은 주문 서비스에서 `Apache Kafka` 혹은 데이터베이스 둘 중 하나에만 쓰기 동작을 수행해 일관성을 보장하는 것이다. 
우선 주문 서비스에서 `Apache Kafka` 에만 새로운 주문에 대한 이벤트를 전송하고 해당 이벤트를 받은 이후 새로운 주문 레코드를 `INSERT` 하는 경우이다. 
하지만 이런 방식을 사용하면 전체 주문을 조회하는 경우 비동기라는 특성으로 인해 새로운 주문이 누락될 수 있다는 문제점이 있다.  

다음으로 알아볼 방법이 데이터베이스에 동기적으로 쓰고, 이를 기반으로 `Apache Kafka` 에 메시지를 보내는 경우인데 이것을 `Outbox Pattern` 이라고 부른다. 
이에 대한 내용은 아래 챕터에서 별도로 다룬다.  


### Outbox Pattern
`Outbox Pattern` 의 기반 아이디어는 데이터베이스에 이벤트를 담는 `Outbox` 테이블을 두는 것이다. 
주문 서비스에서 새로운 주문이 들어오면 신규 주문에 대한 레코드를 `INSERT` 하고, 
동일 트랜잭션에서 `Outbox` 테이블에도 해당 이벤트를 나타내는 레코드를 `INSERT` 하는 방식이다.  

`Outbox` 테이블에 추가되는 레코드는 발생한 이벤트를 의미한다. 
이는 신규 주문을 의미하는 이벤트를 나타내는 `JSON` 일 수도 있고, 주문 변경에 대한 이벤트일 수도있다. 
그리고 필요에 따라 주문을 식별하는 식별자나 타입등의 이벤트 처리를 위한 다양한 컨텍스트를 포함 할 수 있다.  

그리고 `Outbox` 테이블의 변경을 모니터링하는 비동기 프로세스가 `Apache Kafka` 로 해당 테이블의 변경사항을 전파한다. 
이러한 개념을 통해 우리는 신규 주문에 대한 데이터를 `INSERT` 하는 동작과 신규 주문 이벤트를 전파하는 것을 하나의 데이터베이스 트랜잭션으로 묶을 수 있다. 
이는 신규 주문에 대한 데이터베이스 쓰기 동작과 이벤트 전파 동작이 모두 커밋되어 성공하거나, 둘중 하나라도 실패해 모두 실패하는 결과를 얻을 수 있다. 
또한 신규 주문 이후 바로 전체 주문을 조회하더라도 자신이 쓴 주문을 포함해 모두 조회 할 수도 있다.  

여기서 우리가 좀 더 알아봐야 할 것은 바로 `Outbox` 테이블의 변경사항을 어떻게 모니터링 하고, 
이를 `Apache Kafka` 로 밀어 넣어주냐인데 우리는 `Debezium` 과 `CDC`(데이터 변경 캡쳐)를 사용해 이를 손쉽게 해결하고 활용 할 수 있다.  


### CDC
`CDC` 는 소스의 변경을 캡쳐해 타겟이 되는 곳으로 전송하는 것을 의미한다. 
여기서는 `Apache Kafka` 에서 활용할 수 있는 `Debezium CDC` 를 사용할 예정이므로 이를 기준으로 내용을 기술한다. 
`Debezium CDC` 는 테이블을 폴링(조회)하는 방식이 아닌 변경 로그를 기반으로 소스가 되는 데이터 테이블의 변경사항을 캡쳐한다. 
그러므로 다른 방식의 캡쳐와 비교해 낮은 오버해드와 실시간성 및 정확도에 큰 이점이 있다. 
관련해서는 [여기](https://debezium.io/blog/2018/07/19/advantages-of-log-based-change-data-capture/)
에서 상세한 내용을 확인 할 수 있다.   

이후 예제에서는 앞서 설명한 `Outbox Table` 을 `CDC` 를 통해 `Apache Kafka Topic` 에 실시간 스트리밍하는 목적으로 활용할 예정이다. 
그러면 `Outbox Topic` 을 구독하는 여타 서비스에서 이벤트를 받아 필요한 비지니스를 목적에 맞게 수행할 수 있다.  

아래 그림을 보면 데모 애플리케이션 구성과 전체적인 이벤트 흐름을 파악할 수 있다. 
`order-service` 에서 새로운 주문 레코드를 `INSERT` 하고 동일 트랜잭션에서 `Outbox` 테이블에도 해당 이벤트를 나타내는 레코드를 `INSERT` 한다. 
그리면 `CDC` 가 `Outbox` 테이블의 변경을 캡쳐해 이를 `Apache Kafka Topic` 으로 전송하게 된다. 
그리고 해당 `Topic` 을 구독하는 `shipment-service` 는 이벤트 내용을 받아 새로운 배송 레코드를 `INSERT` 하게된다. 
이는 주문이 수정(취소)되거나 배송이 완료되어 주문 서비스에 알려주는 경우도 동일한 흐름으로 진행된다.  

![그림 1]({{site.baseurl}}/img/kafka/kafka-cdc-outbox-1.drawio.png)  


### Outbox Table
데모에서 사용할 `Outbox Table` 의 스키마는 아래와 같다. 

Column|	Type|	Modifiers
---|---|---
id|	uuid|	not null
aggregatetype|	character varying(255)|	not null
aggregateid|	character varying(255)|	not null
type|	character varying(255)|	not null
payload|	jsonb|	not null

각 스키마 필드의 설명은 아래와 같다. 

- `id` : 각 이벤트 메시지의 고유 `ID` 로 소비자의 실패 상황 등에 재시도가 이뤄질 때 중복 이벤트를 김자하는 목적으로 사용될 수 있다. 
- `aggregatetype` : 이벤트를 `Kafka Topic` 으로 라우팅 할때 사용된다. `주문 서비스` 와 `배송 서비스` 가 있다면 구매에 대한 `Topic` 과 배송에 대한 `Topic` 으로 나눌 수 있다. 해당 타입은 동일한 `aggregate` 내에 포함되는 이벤트라면 동일한 유형을 사용해야 한다. 만약 주문 취소 이벤트가 있다면 이또한 주문과 동일한 유형을 사용해야 한다. 즉 주문 취소도 주문 `Topic` 에 들어가도록 해야한다. 
- `aggregateid` : 각 `aggregatetype` 에서 고유하게 식별될 수 있는 아이디로 이벤트 아이디라고 할 수 있다. 이는 이후 `Kafka Topic` 의 키로 사용된다는 점을 기억해야 한다. `주문 서비스`와 `배송 서비스` 가 있다면 개별 주문의 `ID` 와 개별 배송의 `ID` 가 사용 될 수 있다. 만약 주문 취소 이벤트라면 이또한 동일한 `aggregatetype` 을 사용하므로 주문시에 사용된 주문 `ID` 를 동일하게 사용해야 한다. 이러한 방식으로 각 이벤트를 구독해서 소비할 때 동일한 `aggregatetype`(`Topic`) 이라면 모든 이벤트를 생성된 순서대로 소비할 수 있게 된다. 
- `type` : 이벤트의 유형으로 `OrderCreate` 구매 주문, `OrderCancel` 주문 취소가 될 수 있다. 이는 `Topic` 에서 이벤트를 소비했을 때 적절한 이벤트 핸들러를 트리거할 수 있도록 한다. 
- `payload` : 실제 이벤트 내용을 담는 `JSON` 필드이다. 구매 주문 이벤트라면 주문 테이블에 대한 정보와 더불어 추가적으로 구매자 정보 등이 포함 될 수 있다.  
